{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "pd.options.mode.chained_assignment = None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df_train = pd.read_csv('train_small.csv')\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['competitor1_rate'].unique()\n",
    "# integer without nans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['competitor1_has_availability'].unique()\n",
    "# integer without nans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['competitor1_price_percent_diff'].unique()\n",
    "# float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correct the types\n",
    "df_train['stay_on_saturday'] = df_train['stay_on_saturday'].astype('bool')\n",
    "df_train['random_sort'] = df_train['random_sort'].astype('bool')\n",
    "df_train['clicked'] = df_train['clicked'].astype('bool')\n",
    "df_train['booked'] = df_train['booked'].astype('bool')\n",
    "df_train['is_brand'] = df_train['is_brand'].astype('bool')\n",
    "df_train['timestamp'] = pd.to_datetime(df_train['timestamp'])\n",
    "# only change price percent diff\n",
    "cols_comp = [col for col in df_train.columns if 'price_percent_diff' in col]\n",
    "df_train[cols_comp] = df_train[cols_comp].astype('float')\n",
    "\n",
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.1/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes.to_excel('dtypes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.timestamp.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d datapoints and %d columns.'%(df_train.shape[0], df_train.shape[1]))\n",
    "print('There are %d unique searches.'%len(df_train['search_id'].unique()))\n",
    "print('The data is shows the searches done within less than 1 year.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['search_year'] = pd.DatetimeIndex(df_train['timestamp']).year\n",
    "df_train['search_month'] = pd.DatetimeIndex(df_train['timestamp']).month\n",
    "df_train['search_dayofweek'] = pd.DatetimeIndex(df_train['timestamp']).dayofweek\n",
    "df_train['search_dayofyear'] = pd.DatetimeIndex(df_train['timestamp']).dayofyear\n",
    "df_train['search_hour'] = pd.DatetimeIndex(df_train['timestamp']).hour\n",
    "df_train['search_quarter'] = pd.DatetimeIndex(df_train['timestamp']).quarter\n",
    "\n",
    "# for deeper analysis:\n",
    "# some holidays, business day?, business hour?, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any duplicate records?\n",
    "df_train[df_train.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# are there any missing values?\n",
    "print('There are %d missing values.'%df_train.isna().sum().sum())\n",
    "print()\n",
    "ds = df_train.isna().sum()\n",
    "cols_missing = ds[ds != 0].sort_values(ascending=False)/len(df_train)*100\n",
    "\n",
    "print(cols_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe(include=['bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more than one click in the search?\n",
    "\n",
    "df_ = df_train.groupby('search_id')['clicked'].sum().sort_values()\n",
    "print(df_.value_counts(normalize=True))\n",
    "df_\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train[df_train['search_id'] == 14059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_train[['listing_id', 'clicked', 'booked']]\n",
    "df_['clicked'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[df_['clicked'] == 1]['booked'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTR/CR\n",
    "\n",
    "# so slow running, can do better\n",
    "\n",
    "df_r = pd.DataFrame()\n",
    "\n",
    "counts = []\n",
    "lists = []\n",
    "clicks = []\n",
    "books = []\n",
    "\n",
    "for l in df_train['listing_id'].unique():\n",
    "    df_ = df_train[df_train['listing_id'] == l]\n",
    "    counts.append(len(df_))\n",
    "    lists.append(l)\n",
    "    clicks.append(len(df_[df_['clicked'] == 1]))\n",
    "    books.append(len(df_[df_['booked'] == 1]))\n",
    "   \n",
    "df_r['listing_id'] = lists\n",
    "df_r['counts'] = counts\n",
    "df_r['books'] = books\n",
    "df_r['clicks'] = clicks\n",
    "df_r['click_thru_rate'] = df_r['clicks'] / df_r['counts']\n",
    "df_r['conversion_rate'] = df_r['books'] / df_r['counts']\n",
    "df_r['listing_review_score'] = df_train['listing_review_score'] \n",
    "df_r['listing_stars'] = df_train['listing_stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('%d listings have 100%% click through rate.'%len(df_r[df_r['click_thru_rate'] == 1])\n",
    ")\n",
    "\n",
    "print('%d listings have 100%% conversion rate.'%len(df_r[df_r['conversion_rate'] == 1])\n",
    ")\n",
    "\n",
    "print(len(df_r[df_r['conversion_rate'] == 1])/len(df_train['listing_id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = df_train['search_id'].unique()\n",
    "'There are %d searches'%len(searches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <html><p style='color: #FF3341'> add</p></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many of the searched ended up with a booking\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# check if the data has no discrepancies\n",
    "\n",
    "# check if each search is has only one timestamp\n",
    "# check if each search is done only on one website\n",
    "# check if each search has only one country code\n",
    "\n",
    "cols_disc_check = ['timestamp', 'site_id', 'user_country_id', 'user_hist_stars',\n",
    "                   'user_hist_paid', 'num_adults', 'num_kids', 'num_rooms',\n",
    "                   'destination_id', 'length_of_stay', 'booking_window',\n",
    "                   'stay_on_saturday']\n",
    "for s in searches:\n",
    "    \n",
    "    for c in cols_disc_check:\n",
    "        if(len(df_train[df_train['search_id'] == s][c].unique()) != 1):\n",
    "            print(c, s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_country_id versus listing_country_id\n",
    "print('Have users from %d different countries.'%len(df_train['user_country_id'].unique()))\n",
    "print('Have listings in %d different countries.'%len(df_train['listing_country_id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each search how many datapoints and how many unique listings\n",
    "is_repeat = 0\n",
    "\n",
    "for s in searches:\n",
    "    \n",
    "    df_ = df_train[df_train['search_id'] == s]\n",
    "    len_lists = len(df_)\n",
    "    len_lists_unique = len(df_['listing_id'].unique())\n",
    "    \n",
    "    if(len_lists_unique != len_lists):\n",
    "        print(s, 'A listing is displayed more than once.')\n",
    "        is_repeat = 1\n",
    "\n",
    "if(~is_repeat):\n",
    "    print('Within each search, there is only one listing per hotel.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_id\n",
    "len(df_train['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any customer who rated the hotel\n",
    "# but have no purchases for that hotel\n",
    "\n",
    "si = df_train[(df_train['user_hist_paid'].isna()) & (~df_train['user_hist_stars'].isna())]['search_id'].unique()\n",
    "print('In the search %d, the user hasn\\'t purchased \\\n",
    "anything on the website but there is a rating by the customer.\\\n",
    " There should be a mistake in the dataset, hence I will \\\n",
    "discard the records for search %d.'%(si, si))\n",
    "\n",
    "df_train = df_train[~df_train['search_id'].isin(si)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time customer ratio\n",
    "df_ = df_train[['search_id', 'user_hist_paid']].drop_duplicates()\n",
    "ftr = len(df_[df_['user_hist_paid'].isna()])/len(df_)*100\n",
    "print('%d%% of the searches are done by a first time customer.\\n'%ftr)\n",
    "# if that is unreliable, use this\n",
    "\n",
    "df_ = df_train[['search_id', 'user_country_id', 'user_hist_stars', 'user_hist_paid']]\n",
    "len_all = len(df_)\n",
    "df_ = df_[~df_.isna().any(axis=1)]\n",
    "df_['user_id'] = df_['user_country_id'].astype('str') + '|' + df_['user_hist_stars'].astype('str') + '|' + df_['user_hist_paid'].astype('str')\n",
    "len_not_first = len(df_[~df_['user_hist_paid'].isna()]['user_id'].unique())\n",
    "first_time_ratio = (1 - len_not_first/len_all)*100\n",
    "\n",
    "print('There is no user ID on the data to say whether \\\n",
    "a user is a first-time customer. The user_hist_stars \\\n",
    "and user_hist_paid values migth be unreliable.\\\n",
    " Therefore, we can create a user ID using user-related \\\n",
    "data to give a rough conlusion. Discarding null data, \\\n",
    "there are supposedly %d users \\\n",
    "with %d different related searches. This gives that \\\n",
    "roughly %.2f percent of the\\\n",
    " searches are done by a first-time customer.\\\n",
    "'%(len_not_first, len(df_['search_id'].unique()), first_time_ratio))\n",
    "\n",
    "print('\\nCombining these two methods, we can say that \\\n",
    "the majority of the searches are done by a \\\n",
    "first-time customer (a customer who has never \\\n",
    "booked a hotel on the website) or an anonymous user.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings\n",
    "hotels = df_train['listing_id'].unique()\n",
    "countries = df_train['listing_country_id'].unique()\n",
    "\n",
    "print('There are %d hotels listed in the data, located in %d different countries\\\n",
    ".\\n'%(len(hotels), len(countries)))\n",
    "\n",
    "# pie chart\n",
    "df_ = df_train['listing_country_id'].value_counts().to_frame()\n",
    "quantile = df_.quantile(0.97).iloc[0]\n",
    "df_q = df_[df_['listing_country_id'] > quantile]\n",
    "others = df_[df_['listing_country_id'] <= quantile]['listing_country_id'].sum()\n",
    "new_row = pd.DataFrame([others], columns=['listing_country_id'], index=['others'])\n",
    "df_q = pd.concat([df_q, new_row])\n",
    "\n",
    "print('\\nPie chart showing top %d countries.'%len(df_q))\n",
    "\n",
    "df_q.plot.pie(y='listing_country_id')\n",
    "plt.show()\n",
    "\n",
    "# how many hotels has ratings\n",
    "len_rated = len(df_train[df_train['listing_stars'] != 0]['listing_id'].unique())\n",
    "len_reviewed = len(df_train[df_train['listing_review_score'] != 0]['listing_id'].unique())\n",
    "\n",
    "df_both = df_train[(df_train['listing_review_score'] != 0) & \n",
    "               (df_train['listing_stars'] != 0)]['listing_id'].unique()\n",
    "\n",
    "\n",
    "print('Roughly %.2f%% of the hotels are rated and %.2f%% are reviewed,\\\n",
    " only %.2f%% have both ratings and reviews.\\\n",
    " \\n'%(len_rated/len(hotels)*100, len_reviewed/len(hotels)*100, \n",
    "      len(df_both)/len(hotels)*100))\n",
    "\n",
    "# hotel stars and reviews- compare\n",
    "df_ = df_train[(df_train['listing_stars'] != 0) & (df_train['listing_review_score'] != 0)][['listing_stars', 'listing_review_score']]\n",
    "df_['score_diff'] = abs(df_['listing_stars'] - df_['listing_review_score'])\n",
    "df_.boxplot()\n",
    "plt.title('Rating and review score differences (both rated&reviewed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many time each hotel listed\n",
    "df_train['listing_id'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_score1 and location_score2, which of them affects the booking ratio more\n",
    "# hotel stars and reviews- compare\n",
    "df_ = df_train[['location_score1', 'location_score2']]\n",
    "\n",
    "# how many hotels has location scores\n",
    "len_score1 = len(df_train[~df_train['location_score1'].isna()]['listing_id'].unique())\n",
    "len_score2 = len(df_train[~df_train['location_score2'].isna()]['listing_id'].unique())\n",
    "\n",
    "df_both = df_train[(~df_train['location_score1'].isna()) & \n",
    "               (~df_train['location_score2'].isna())]['listing_id'].unique()\n",
    "\n",
    "\n",
    "print('%.2f%% of the hotels has location_score1 and %.2f%% location_score_2,\\\n",
    " only %.2f%% have both.\\\n",
    " \\n'%(len_score1/len(hotels)*100, len_score2/len(hotels)*100, \n",
    "      len(df_both)/len(hotels)*100))\n",
    "\n",
    "print(df_.describe())\n",
    "df_.boxplot()\n",
    "plt.title('Location score differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is log_historical_price exactly?\n",
    "print(df_train['log_historical_price'].describe())\n",
    "\n",
    "# case 1: listing_id = 3625\n",
    "h_ = 3625\n",
    "\n",
    "df_ = df_train[(df_train['listing_id'] == h_) & (df_train['log_historical_price'] != 0)]\n",
    "prices = df_['log_historical_price'].unique()\n",
    "day_range = (df_['timestamp'].max() - df_['timestamp'].min()).days\n",
    "\n",
    "print('Analysis of a hotel\\'s historical prices:\\n\\\n",
    "The hotel %d has had these prices over the periods:\\n\\\n",
    "'%h_, prices)\n",
    "\n",
    "print('\\nSince the data for hotel %d spans over %d days,\\\n",
    " there is a low chance that the hotel was sold %d times \\\n",
    "during that period.'%(h_, day_range, len(prices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many times each hotel was sold\n",
    "df_times_sold = pd.DataFrame()\n",
    "t = []\n",
    "for h in hotels:\n",
    "    t.append(len(df_train[(df_train['listing_id'] == h) & (df_train['log_historical_price'] != 0)]['log_historical_price'].unique()))\n",
    "  \n",
    "df_times_sold['hotel'] = hotels\n",
    "df_times_sold['times_sold'] = t\n",
    "\n",
    "df_times_sold.sort_values(by=['times_sold'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2: listing_id = 30992\n",
    "h_ = 30992\n",
    "\n",
    "df_ = df_train[(df_train['listing_id'] == h_) & (df_train['log_historical_price'] != 0)]\n",
    "prices = df_['log_historical_price'].unique()\n",
    "day_range = (df_['timestamp'].max() - df_['timestamp'].min()).days\n",
    "\n",
    "print('Analysis of a hotel\\'s historical prices:\\n\\\n",
    "The hotel %d has had these prices over the periods:\\n\\\n",
    "'%h_, prices)\n",
    "\n",
    "print('\\nSince the data for hotel %d spans over %d days,\\\n",
    " there is a low chance that the hotel was sold %d times\\\n",
    " during that period.'%(h_, day_range, len(prices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'From this analysis, I conclude that historical price \\\n",
    "means something else. It might be the historical prices\\\n",
    " of the listings, which makes more sense in this way.\\\n",
    " From now on, I will treat it like so.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a feature: how many a times a listing is sold\n",
    "print(df_train.shape)\n",
    "df_train = df_train.merge(df_times_sold, how='left', left_on='listing_id', right_on='hotel').drop(['hotel'], axis=1)\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many listings listed in each search result\n",
    "for s in searches:\n",
    "    df_ = df_train[df_train['search_id'] == s]\n",
    "    n_unique_listing = len(df_['listing_id'].unique())\n",
    "    n_unique_position = len(df_['listing_position'].unique())\n",
    "    if(n_unique_listing != n_unique_position):\n",
    "        print('Not match: %d'%s)\n",
    "        \n",
    "df_train.groupby('search_id')['listing_position'].count().hist(figsize=(10, 5))\n",
    "print('How many listings in each search result:')\n",
    "print(df_train.groupby('search_id')['listing_position'].count())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does listing_position affect the click/purchase?\n",
    "df_ = df_train[['listing_position', 'clicked', 'booked']]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "lim1 = df_[df_['booked'] == 1]['listing_position'].hist(ax=axes[0]).get_ylim()[1]\n",
    "lim2 = df_[df_['clicked'] == 1]['listing_position'].hist(ax=axes[1]).get_ylim()[1]\n",
    "\n",
    "axis_lim = max(lim1, lim2)\n",
    "axes[0].set_ylim(0, axis_lim)\n",
    "axes[1].set_ylim(0, axis_lim)\n",
    "\n",
    "axes[0].set_title('booked')\n",
    "axes[1].set_title('clicked')\n",
    "print(df_.describe())\n",
    "print('\\nHow the listing position affects booking and clicking')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['first_position'] = df_['listing_position'].apply(lambda x: 1 if x == 1 else 0)\n",
    "len_b = df_[df_['first_position'] == 1]['booked'].sum()\n",
    "len_c = df_[df_['first_position'] == 1]['clicked'].sum()\n",
    "len_first = len(df_[df_['first_position'] == 1])\n",
    "\n",
    "print('%.2f %% of the listings in the first position are clicked, \\\n",
    "%.2f %% booked.'%(len_c/len_first*100, len_b/len_first*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price of the hotel\n",
    "print(df_train['price_usd'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_promotion\n",
    "print(df_train['has_promotion'].unique())\n",
    "\n",
    "df_train[['has_promotion', 'clicked', 'booked']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_value vs price_usd\n",
    "\n",
    "#discrepancy?\n",
    "l = len(df_train[(df_train['booked'] == 0) & (~df_train['booking_value'].isna())])\n",
    "print('There are %d record showing that booking value exists\\\n",
    "given that the listing is booked.\\n'%l)\n",
    "\n",
    "df_ = df_train[df_train['booked'] == 1][['booking_value', 'price_usd']]\n",
    "df_['price_diff'] = df_train['booking_value'] - df_train['price_usd']\n",
    "print(df_['price_diff'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination_id, for each searh how many listing_country_id\n",
    "print('There are %d destinations. Assuming, these destinations\\\n",
    "are the locations where the user want to book a hotel room in,\\\n",
    " I already checked if each search result has the same destination ID.\\\n",
    " '%len(set(df_train['destination_id'])))\n",
    "df_ = df_train[['booked', 'destination_id']].drop_duplicates()\n",
    "\n",
    "df_['destination_id'].hist()\n",
    "plt.title('distribution of destinations searched')\n",
    "plt.show()\n",
    "\n",
    "print('The data seems evenly distributed over destionations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_train.groupby('destination_id').sum()['times_sold'].to_frame().reset_index()\n",
    "print(df_['times_sold'].describe())\n",
    "print(df_['times_sold'].plot())\n",
    "#quantile = df_[df_['times_sold'] != 0]['times_sold'].quantile(0.99)\n",
    "#df_q = df_[df_['times_sold'] > quantile]\n",
    "\n",
    "df_ = df_.sort_values(by='times_sold', ascending=False)\n",
    "print(df_['times_sold'].iloc[0]/df_['times_sold'].sum())\n",
    "print(len(df_train[df_train['destination_id'] == 8192][['search_id', 'destination_id']].drop_duplicates())/len(df_train['search_id'].unique()))\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_window statistics\n",
    "df_ = df_train[['search_id', 'booking_window']].drop_duplicates()\n",
    "print(df_['booking_window'].value_counts())\n",
    "print('\\n%.2f%% of the booking windows searched is 1 day.\\\n",
    "'%(df_['booking_window'].value_counts().head().iloc[0]/len(df_)*100))\n",
    "df_['booking_window'].hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n%.2f%% of searches has no booking window.\\\n",
    "'%(df_['booking_window'].value_counts().head().iloc[1]/len(df_)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n%.2f%% of searches has 2-day booking window.\\\n",
    "'%(df_['booking_window'].value_counts().head().iloc[2]/len(df_)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_adults/num_kids/num_rooms/length_of_stay\n",
    "# are these the same for each search?\n",
    "\n",
    "print('Since there is only one value for num_adults/num_kids/\\\n",
    "num_rooms/length_of_stay for each search, these are specified \\\n",
    "by the user.\\n')\n",
    "\n",
    "df_ = df_train[['search_id', 'num_adults', 'num_kids', 'num_rooms', 'length_of_stay']]\n",
    "df_.drop_duplicates(inplace=True)\n",
    "\n",
    "print('Different lengths of stays:\\n')\n",
    "length_of_stays = df_['length_of_stay'].sort_values().unique()\n",
    "print(length_of_stays)\n",
    "print()\n",
    "df_['length_of_stay'].hist(figsize=(10, 5), bins=length_of_stays)\n",
    "plt.title('Lenth_of_stay distribution')\n",
    "plt.show()\n",
    "\n",
    "print('57 seems odd so let\\'s check it out:\\n')\n",
    "\n",
    "print(df_train[df_train['length_of_stay'] == 57][['clicked', 'booked']])\n",
    "\n",
    "\n",
    "df_['length_of_stay'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many 1-day stays booked?\n",
    "\n",
    "df_ = df_train[df_train['length_of_stay'] == 1][['search_id', 'booked']]\n",
    "df_['booked'] = df_['booked'].apply(lambda x: 1 if x == True else 0)\n",
    "df_.groupby('search_id')['booked'].sum().value_counts(normalize=True)\n",
    "\n",
    "# more:\n",
    "# look at their booking window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stay_on_saturday, ratio of searches including saturday?\n",
    "df_ = df_train[['search_id', 'length_of_stay','stay_on_saturday']]\n",
    "df_.drop_duplicates(inplace=True)\n",
    "\n",
    "print('If the stay lasts more than 6 days then it \\\n",
    "should include at least 1 Saturday.\\n')\n",
    "\n",
    "print('Different lengths of stay with Saturday:\\n')\n",
    "\n",
    "print(df_[df_['stay_on_saturday'] == True]['length_of_stay'].unique())\n",
    "\n",
    "print('\\nDifferent lengths of stay with no Saturday:\\n')\n",
    "\n",
    "print(df_[df_['stay_on_saturday'] == False]['length_of_stay'].unique())\n",
    "\n",
    "print('\\nHow come a stay lasts more than 7 days and \\\n",
    "still has no Saturday stay?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_)):\n",
    "    is_sat = 1 if df_['stay_on_saturday'].iloc[i] == True else 0\n",
    "    times = df_['length_of_stay'].iloc[i] // 7\n",
    "    \n",
    "    if((is_sat == 0) & (times >= 1)):\n",
    "        print('Search %d has a problem.'%df_['search_id'].iloc[i])\n",
    "        break\n",
    "print()\n",
    "print(df_[df_['search_id'] == 30])\n",
    "\n",
    "print('\\n\\nLet\\'s look at search 30:\\n')\n",
    "print('Date: %s\\nWindow: %d\\nLength: %d\\nSaturday: %s'\\\n",
    "%(df_train[df_train['search_id'] == 30]['timestamp'].iloc[0],\n",
    "df_train[df_train['search_id'] == 30]['booking_window'].iloc[0],\n",
    "df_train[df_train['search_id'] == 30]['length_of_stay'].iloc[0],\n",
    "df_train[df_train['search_id'] == 30]['stay_on_saturday'].iloc[0],\n",
    "))\n",
    "\n",
    "print('\\nThis stay seems to include a Saturday (2/3/201) \\\n",
    "and it starts on Sunday.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's include the start date of the stay\n",
    "df_train['stay_start'] = df_train['timestamp'] + df_train['length_of_stay'].apply(timedelta)\n",
    "\n",
    "df_train['stay_year'] = pd.DatetimeIndex(df_train['stay_start']).year\n",
    "df_train['stay_month'] = pd.DatetimeIndex(df_train['stay_start']).month\n",
    "df_train['stay_dayofweek'] = pd.DatetimeIndex(df_train['stay_start']).dayofweek\n",
    "df_train['stay_dayofyear'] = pd.DatetimeIndex(df_train['stay_start']).dayofyear\n",
    "df_train['stay_hour'] = pd.DatetimeIndex(df_train['stay_start']).hour\n",
    "df_train['stay_quarter'] = pd.DatetimeIndex(df_train['stay_start']).quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stay start days with saturday:', df_train[df_train['stay_on_saturday'] == True]['stay_dayofweek'].unique()\n",
    ")\n",
    "print('\\nI couldn\\'t understand this feature so I will continue \\\n",
    "without more analysis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_train[['search_id', 'destination_id', 'stay_dayofyear', 'stay_month', 'stay_dayofweek']]\n",
    "df_.drop_duplicates(inplace=True)\n",
    "print(df_['destination_id'].value_counts(ascending=False, normalize=True).head())\n",
    "print('\\n')\n",
    "print(df_['stay_dayofyear'].value_counts(ascending=False, normalize=True))\n",
    "print('\\n')\n",
    "print(df_['stay_month'].value_counts(ascending=False, normalize=True))\n",
    "print('\\n')\n",
    "print(df_['stay_dayofweek'].value_counts(ascending=False, normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_[df_['stay_month'].isin([6, 3, 5, 4])])/len(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance_to_dest\n",
    "df_train['distance_to_dest'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a listing is in more than one site?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many of the clicked ones booked?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill nulls\n",
    "\n",
    "\n",
    "# listing_review_score:\n",
    "# average\n",
    "print(len(df_train['listing_id'].unique()))\n",
    "\n",
    "df_ = df_train[['listing_id', 'listing_review_score']].drop_duplicates()\n",
    "score_avg = df_['listing_review_score'].mean()\n",
    "print(df_.shape)\n",
    "df_train['listing_review_score'] = df_train['listing_review_score'].fillna(score_avg)\n",
    "\n",
    "\n",
    "# distance_to_dest:\n",
    "# average\n",
    "print(len(df_train['listing_id'].unique()))\n",
    "\n",
    "df_ = df_train[['search_id', 'distance_to_dest']].drop_duplicates()\n",
    "dist_avg = df_['distance_to_dest'].mean()\n",
    "print(df_.shape)\n",
    "df_train['distance_to_dest'] = df_train['distance_to_dest'].fillna(dist_avg)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitor info\n",
    "df_train = df_train.rename(columns={'competitor1_rate':'cr1',\n",
    "                 'competitor1_has_availability':'cha1', \n",
    "                 'competitor1_price_percent_diff':'cppf1',\n",
    "                 'competitor2_rate':'cr2', \n",
    "                 'competitor2_has_availability':'cha2',\n",
    "                 'competitor2_price_percent_diff':'cppf2', \n",
    "                 'competitor3_rate':'cr3',\n",
    "                 'competitor3_has_availability':'cha3', \n",
    "                 'competitor3_price_percent_diff':'cppf3',\n",
    "                 'competitor4_rate':'cr4', \n",
    "                 'competitor4_has_availability':'cha4',\n",
    "                 'competitor4_price_percent_diff':'cppf4', \n",
    "                 'competitor5_rate':'cr5',\n",
    "                 'competitor5_has_availability':'cha5', \n",
    "                 'competitor5_price_percent_diff':'cppf5',\n",
    "                 'competitor6_rate':'cr6', \n",
    "                 'competitor6_has_availability':'cha6',\n",
    "                 'competitor6_price_percent_diff':'cppf6', \n",
    "                 'competitor7_rate':'cr7',\n",
    "                 'competitor7_has_availability':'cha7', \n",
    "                 'competitor7_price_percent_diff':'cppf7',\n",
    "                 'competitor8_rate':'cr8', \n",
    "                 'competitor8_has_availability':'cha8',\n",
    "                 'competitor8_price_percent_diff':'cppf8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_competitive = ['cr1', 'cr2', 'cr3', 'cr4', 'cr5', 'cr6', 'cr7', 'cr8',\n",
    "                    'cha1', 'cha2', 'cha3', 'cha4', 'cha5', 'cha6', 'cha7', 'cha8', \n",
    "                    'cppf1', 'cppf2', 'cppf3', 'cppf4', 'cppf5', 'cppf6', 'cppf7', 'cppf8']\n",
    "\n",
    "df_ = df_train[cols_competitive]\n",
    "\n",
    "df_.isnull().sum().sort_values(ascending=False).iloc[0]/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Competitor data has a lot of missing values. \\\n",
    "We can either combine them all to create a feature or\\\n",
    " we can fill them. I prefer not to fill\\\n",
    " missing values as the ratio of missing values is too much.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cr = df_train[['booked', 'cr1', 'cr2', 'cr3', 'cr4', 'cr5', 'cr6', 'cr7', 'cr8']]\n",
    "\n",
    "\n",
    "#df_cr = df_cr.dropna(subset=['cr1', 'cr2', 'cr3', 'cr4', 'cr5', 'cr6', 'cr7', 'cr8'], how='all', axis=0)\n",
    "df_cr['info'] = df_cr.apply(lambda x: 1 if x.count() - 1 > 1 else 0, axis=1)\n",
    "df_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price difference, how it affects?\n",
    "df_ = df_train[['booked', 'cppf1', 'cppf2', 'cppf3', 'cppf4', 'cppf5',\n",
    "                'cppf6', 'cppf7', 'cppf8']]\n",
    "df_.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr = ['site_id', 'user_country_id',\n",
    "       'user_hist_stars', 'user_hist_paid', 'listing_country_id', 'listing_id',\n",
    "       'listing_stars', 'listing_review_score', 'is_brand', 'location_score1',\n",
    "       'location_score2', 'log_historical_price', 'listing_position',\n",
    "       'price_usd', 'has_promotion', 'destination_id', 'length_of_stay',\n",
    "       'booking_window', 'num_adults', 'num_kids', 'num_rooms',\n",
    "       'stay_on_saturday', 'log_click_proportion', 'distance_to_dest',\n",
    "       'random_sort', 'cr1', 'cr2', 'cr3', 'cr4', 'cr5', 'cr6', 'cr7', 'cr8',\n",
    "                    'cha1', 'cha2', 'cha3', 'cha4', 'cha5', 'cha6', 'cha7', 'cha8', \n",
    "                    'cppf1', 'cppf2', 'cppf3', 'cppf4', 'cppf5', 'cppf6', 'cppf7', 'cppf8',\n",
    "       'clicked', 'booking_value', 'booked', 'times_sold',\n",
    "       'search_year', 'search_month', 'search_dayofweek', 'search_dayofyear',\n",
    "       'search_hour', 'search_quarter', 'stay_year', 'stay_month',\n",
    "       'stay_dayofweek', 'stay_dayofyear', 'stay_hour', 'stay_quarter',\n",
    "       'stay_start']\n",
    "\n",
    "df_corr = df_train[list_corr].corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "cols = []\n",
    "corrs = []\n",
    "\n",
    "for c in df_corr.columns:\n",
    "    for i in df_corr.index:\n",
    "        co = abs(df_corr[c].loc[i])\n",
    "        if(c == i):\n",
    "            continue\n",
    "        if(co >= 0.85):\n",
    "            if((c in cols) & (i in indices)):\n",
    "                continue\n",
    "                \n",
    "            indices.append(i)\n",
    "            cols.append(c)\n",
    "            corrs.append(co)\n",
    "            \n",
    "df_ = pd.DataFrame()\n",
    "df_['feat1'] = indices\n",
    "df_['feat2'] = cols\n",
    "df_['corr'] = corrs\n",
    "df_.drop_duplicates(inplace=True)\n",
    "df_\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "df_corr['clicked'].sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr['booked'].sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('For now, I will discard competitors\\' data.')\n",
    "\n",
    "df_train = df_train.drop(cols_competitive, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Let\\'s drop IDs: %s\\n'%['search_id', 'listing_id', 'site_id',\n",
    "                         'user_country_id', 'listing_country_id',\n",
    "                          'destination_id'\n",
    "                         ])\n",
    "df_train = df_train.drop(['search_id', 'listing_id', 'site_id',\n",
    "                         'user_country_id', 'listing_country_id',\n",
    "                          'destination_id'\n",
    "                         ], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the train data: ', df_train.shape)\n",
    "\n",
    "cols_time = ['search_year', 'search_month', 'search_dayofweek', 'search_dayofyear',\n",
    "       'search_hour', 'search_quarter', 'stay_year', 'stay_month',\n",
    "       'stay_dayofweek', 'stay_dayofyear', 'stay_hour', 'stay_quarter']\n",
    "\n",
    "df_ = df_train[cols_time].drop_duplicates()\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df_vif = pd.DataFrame()\n",
    "\n",
    "X_ = df_\n",
    "df_vif['feats'] = X_.columns\n",
    "df_vif['VIF_value'] = [vif(X_.values, i) for i in range(X_.shape[1])]\n",
    "df_vif\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns: unnecessary\n",
    "cols_to_drop1 = ['search_year', 'search_month', 'search_quarter',\n",
    "               'stay_year', 'stay_month', 'stay_hour', \n",
    "               'stay_quarter']\n",
    "\n",
    "df_vif = pd.DataFrame()\n",
    "\n",
    "X_ = df_.drop(cols_to_drop1, axis=1)\n",
    "\n",
    "df_vif['feats'] = X_.columns\n",
    "df_vif['VIF_value'] = [vif(X_.values, i) for i in range(X_.shape[1])]\n",
    "df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop2 =['search_dayofyear']\n",
    "\n",
    "df_vif = pd.DataFrame()\n",
    "\n",
    "X_ = X_.drop(cols_to_drop2, axis=1)\n",
    "\n",
    "df_vif['feats'] = X_.columns\n",
    "df_vif['VIF_value'] = [vif(X_.values, i) for i in range(X_.shape[1])]\n",
    "df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['timestamp', 'listing_position',\n",
    "                         'booking_window', 'stay_start',\n",
    "                          'user_hist_stars', 'user_hist_paid',\n",
    "                          'location_score2', 'log_click_proportion',\n",
    "                          'booking_value', 'search_year', \n",
    "                          'search_month', 'search_quarter',\n",
    "                           'stay_year', 'stay_month', 'stay_hour', \n",
    "                           'stay_quarter', 'search_dayofyear'\n",
    "                         ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clicked'] = df_train['clicked'].apply(lambda x: 1 if x== True else 0)\n",
    "df_train['booked'] = df_train['booked'].apply(lambda x: 1 if x== True else 0)\n",
    "df_train['stay_on_saturday'] = df_train['stay_on_saturday'].apply(lambda x: 1 if x== True else 0)\n",
    "df_train['random_sort'] = df_train['random_sort'].apply(lambda x: 1 if x== True else 0)\n",
    "df_train['is_brand'] = df_train['is_brand'].apply(lambda x: 1 if x== True else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df_vif = pd.DataFrame()\n",
    "\n",
    "X_ = df_train.drop(['booked'], axis=1)\n",
    "df_vif['feats'] = X_.columns\n",
    "df_vif['VIF_value'] = [vif(X_.values, i) for i in range(X_.shape[1])]\n",
    "df_vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.plot.scatter('listing_stars', 'listing_review_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_vif_qe10 = list(df_vif[df_vif['VIF_value'] >= 10]['feats'])\n",
    "print('We have collinearity between the features. \\\n",
    "The most predictible features using other features:\\n\\\n",
    "%s'%cols_vif_qe10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "def prep_data(df):\n",
    "    \n",
    "    ##########################\n",
    "    # correct the types\n",
    "    df['stay_on_saturday'] = df['stay_on_saturday'].astype('bool')\n",
    "    df['random_sort'] = df['random_sort'].astype('bool')\n",
    "    df['clicked'] = df['clicked'].astype('bool')\n",
    "    df['booked'] = df['booked'].astype('bool')\n",
    "    df['is_brand'] = df['is_brand'].astype('bool')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    # add date/time features\n",
    "    df['search_dayofweek'] = pd.DatetimeIndex(df['timestamp']).dayofweek\n",
    "    df['search_hour'] = pd.DatetimeIndex(df['timestamp']).hour\n",
    "    \n",
    "    ##########################\n",
    "    # drop records where a user hasn't purchased anything but rated\n",
    "    si = df[(df['user_hist_paid'].isna()) & (~df['user_hist_stars'].isna())]['search_id'].unique()\n",
    "    df = df[~df['search_id'].isin(si)]\n",
    "    \n",
    "    ##########################\n",
    "    # add feature: how many times a listing sold (could be done faster)\n",
    "    df_times_sold = pd.DataFrame()\n",
    "    t = []\n",
    "    hotels = df['listing_id'].unique()\n",
    "    for h in hotels:\n",
    "        t.append(len(df[(df['listing_id'] == h) & (df['log_historical_price'] != 0)]['log_historical_price'].unique()))\n",
    "    df_times_sold['hotel'] = hotels\n",
    "    df_times_sold['times_sold'] = t\n",
    "    df = df.merge(df_times_sold, how='left', left_on='listing_id', right_on='hotel').drop(['hotel'], axis=1)\n",
    "    \n",
    "    ##########################\n",
    "    # Let's include the start date of the stay \n",
    "    df['stay_start'] = df['timestamp'] + df['length_of_stay'].apply(timedelta)\n",
    "    df['stay_dayofweek'] = pd.DatetimeIndex(df['stay_start']).dayofweek\n",
    "    df['stay_dayofyear'] = pd.DatetimeIndex(df['stay_start']).dayofyear  \n",
    "\n",
    "    ##########################   \n",
    "    # fillna\n",
    "    \n",
    "    # listing_review_score: average\n",
    "    df_ = df[['listing_id', 'listing_review_score']].drop_duplicates()\n",
    "    score_avg = df_['listing_review_score'].mean()\n",
    "    df['listing_review_score'] = df['listing_review_score'].fillna(score_avg)\n",
    "\n",
    "    # distance_to_dest: average\n",
    "    df_ = df[['search_id', 'distance_to_dest']].drop_duplicates()\n",
    "    dist_avg = df_['distance_to_dest'].mean()\n",
    "    df['distance_to_dest'] = df['distance_to_dest'].fillna(dist_avg)\n",
    "\n",
    "    ##########################\n",
    "    # drop competitor data\n",
    "    cols_competitive = ['competitor1_rate', 'competitor1_has_availability', \n",
    "                        'competitor1_price_percent_diff', 'competitor2_rate', \n",
    "                        'competitor2_has_availability', 'competitor2_price_percent_diff', \n",
    "                        'competitor3_rate', 'competitor3_has_availability', \n",
    "                        'competitor3_price_percent_diff', 'competitor4_rate', \n",
    "                        'competitor4_has_availability', 'competitor4_price_percent_diff', \n",
    "                        'competitor5_rate', 'competitor5_has_availability', \n",
    "                        'competitor5_price_percent_diff', 'competitor6_rate', \n",
    "                        'competitor6_has_availability', 'competitor6_price_percent_diff', \n",
    "                        'competitor7_rate', 'competitor7_has_availability', \n",
    "                        'competitor7_price_percent_diff', 'competitor8_rate', \n",
    "                        'competitor8_has_availability', 'competitor8_price_percent_diff']\n",
    "    \n",
    "    df.drop(cols_competitive, axis=1, inplace=True)\n",
    "    \n",
    "    ##########################\n",
    "    # drop columns\n",
    "    cols_to_drop = ['timestamp', 'site_id', 'search_id', \n",
    "                    'listing_id', 'listing_position',\n",
    "                'user_country_id', 'listing_country_id',\n",
    "                 'booking_window', 'destination_id',\n",
    "                'stay_start', 'user_hist_stars', 'user_hist_paid', 'location_score2',\n",
    "             'log_click_proportion', 'booking_value',\n",
    "                   'location_score2']\n",
    "    \n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    ##########################\n",
    "    # True/False -> 1/0\n",
    "    df['clicked'] = df['clicked'].apply(lambda x: 1 if x== True else 0)\n",
    "    df['booked'] = df['booked'].apply(lambda x: 1 if x== True else 0)\n",
    "    df['stay_on_saturday'] = df['stay_on_saturday'].apply(lambda x: 1 if x== True else 0)\n",
    "    df['random_sort'] = df['random_sort'].apply(lambda x: 1 if x== True else 0)\n",
    "    df['is_brand'] = dfn['is_brand'].apply(lambda x: 1 if x== True else 0)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('train_small.csv')\n",
    "df_train = prep_data(df_train)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save for backup\n",
    "df_train_backup = df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the data:', df_train.shape)\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model data\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train.drop(['booked'], axis=1)\n",
    "y = df_train['booked']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print('Dataset is split having %d datapoints in train set and\\\n",
    " %d in test set.'%(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EKSTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTIONS-ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train[df_train['booked'] == 1])/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('train_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# privacy/security issues\n",
    "# user\n",
    "\n",
    "df_ = df_raw[['user_country_id', 'user_hist_stars', 'user_hist_paid']].drop_duplicates()\n",
    "\n",
    "df_uci = df_['user_country_id'].value_counts().to_frame()\n",
    "print(df_uci)\n",
    "list_uci = list(df_uci[df_uci['user_country_id'] == 1].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uhs = df_['user_hist_stars'].value_counts().to_frame()\n",
    "print(df_uhs)\n",
    "list_uhs = list(df_uhs[df_uhs['user_hist_stars'] == 1].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uhp = df_['user_hist_paid'].value_counts().to_frame()\n",
    "print(df_uhp)\n",
    "list_uhp = list(df_uhp[df_uhp['user_hist_paid'] == 1].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[(df_raw['user_hist_paid'].isin(list_uhp)) & \n",
    "       (df_raw['user_hist_stars'].isin(list_uhs)) &\n",
    "       (df_raw['user_country_id'].isin(list_uci))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[df_raw['user_hist_paid'].isin([364.00])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing\n",
    "\n",
    "df_ = df_raw[['listing_country_id', 'listing_id', 'listing_stars',\n",
    "             'listing_review_score', 'is_brand', 'location_score1',\n",
    "             'location_score2', 'log_historical_price', 'price_usd',\n",
    "             'destination_id', 'log_click_proportion']].drop_duplicates()\n",
    "# also competitor data\n",
    "\n",
    "df_uci = df_['user_country_id'].value_counts().to_frame()\n",
    "print(df_uci)\n",
    "list_uci = list(df_uci[df_uci['user_country_id'] == 1].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "   'prop_location_score1', 'prop_log_historical_price',\n",
    "   'price_usd', 'promotion_flag', 'srch_length_of_stay',\n",
    "   'srch_booking_window', 'srch_adults_count', \n",
    "    'srch_children_count', 'srch_room_count',\n",
    "    'srch_saturday_night_bool', 'orig_destination_distance',\n",
    "    'date_time', 'booking_bool'\n",
    "   ]]\n",
    "cols_old = ['prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "   'prop_location_score1', 'prop_log_historical_price',\n",
    "   'price_usd', 'promotion_flag', 'srch_length_of_stay',\n",
    "   'srch_booking_window', 'srch_adults_count', \n",
    "    'srch_children_count', 'srch_room_count',\n",
    "    'srch_saturday_night_bool', 'orig_destination_distance',\n",
    "    'date_time', 'booking_bool'\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_new = ['listing_id', 'listing_stars', 'listing_review_score', \n",
    "                   'is_brand',\n",
    "   'location_score1', 'log_historical_price',\n",
    "   'price_usd', 'has_promotion', 'length_of_stay',\n",
    "   'booking_window', 'num_adults', \n",
    "    'num_kids', 'num_rooms',\n",
    "    'stay_on_saturday', 'distance_to_dest',\n",
    "    'timestamp', 'booked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {}\n",
    "\n",
    "for i, j in zip(cols_old, cols_new):\n",
    "    rename_dict[i] = j\n",
    "\n",
    "df.rename(columns=rename_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'search_dayofweek', 'search_hour', \n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['search_dayofweek'] = pd.DatetimeIndex(df['timestamp']).dayofweek\n",
    "df['search_hour'] = pd.DatetimeIndex(df['timestamp']).hour\n",
    "    \n",
    "\n",
    "#'times_sold',\n",
    "df_times_sold = pd.DataFrame()\n",
    "t = []\n",
    "hotels = df['listing_id'].unique()\n",
    "for h in hotels:\n",
    "    t.append(len(df[(df['listing_id'] == h) & (df['log_historical_price'] != 0)]['log_historical_price'].unique()))\n",
    "df_times_sold['hotel'] = hotels\n",
    "df_times_sold['times_sold'] = t\n",
    "df = df.merge(df_times_sold, how='left', left_on='listing_id', right_on='hotel').drop(['hotel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'stay_dayofweek', 'stay_dayofyear'\n",
    "from datetime import datetime, timedelta\n",
    "df['stay_start'] = df['timestamp'] + df['length_of_stay'].apply(timedelta)\n",
    "df['stay_dayofweek'] = pd.DatetimeIndex(df['stay_start']).dayofweek\n",
    "df['stay_dayofyear'] = pd.DatetimeIndex(df['stay_start']).dayofyear  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['listing_stars', 'listing_review_score', \n",
    "    'is_brand',\n",
    "   'location_score1', 'log_historical_price',\n",
    "   'price_usd', 'has_promotion', 'length_of_stay',\n",
    "   'booking_window', 'num_adults', \n",
    "    'num_kids', 'num_rooms',\n",
    "    'stay_on_saturday', 'distance_to_dest',\n",
    "    'timestamp', 'booked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
